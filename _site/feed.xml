<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-06-20T22:12:23-04:00</updated><id>http://localhost:4000/</id><title type="html">Adventures in Machine Learning and Biology</title><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><entry><title type="html">Getting started in machine learning</title><link href="http://localhost:4000/2019/06/21/getting-started.html" rel="alternate" type="text/html" title="Getting started in machine learning" /><published>2019-06-20T20:00:00-04:00</published><updated>2019-06-20T20:00:00-04:00</updated><id>http://localhost:4000/2019/06/21/getting-started</id><content type="html" xml:base="http://localhost:4000/2019/06/21/getting-started.html">&lt;p&gt;Every so often, a chemist or biologist will ask me how they can get started in machine learning. Here is my current answer:&lt;/p&gt;

&lt;h2 id=&quot;my-experience&quot;&gt;My experience&lt;/h2&gt;

&lt;p&gt;When I started out, I had a strong quantitative background (chemical engineering undergrad, was taking PhD courses in chemical engineering) and some functional skills in programming. From there, I first dove deep into one type of machine learning (Gaussian processes) along with general ML practice (how to set up ML experiments in order to evaluate your models) because that was what I needed for my project. I learned mostly online and by reading papers, but I also took one class on data analysis for biologists that wasn’t ML-focused but did cover programming and statistical thinking. Later, I took a linear algebra class, an ML survey class, and an advanced topics class on structured learning at Caltech. Those helped me obtain a broad knowledge of ML, and then I’ve gained deeper understandings of some subfields that interest me or are especially relevant by reading papers closely (chasing down references and anything I don’t understand and/or implementing the core algorithms myself).&lt;/p&gt;

&lt;h2 id=&quot;general-advice-and-where-to-start&quot;&gt;General advice and where to start&lt;/h2&gt;

&lt;p&gt;More generally, to do applied ML you need to be able to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Put your data into your model.&lt;/li&gt;
  &lt;li&gt;Understand at a high level what the model is doing.&lt;/li&gt;
  &lt;li&gt;Analyze the results.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For 1 and 3, programming is essential. The most popular language for ML right now is Python, but programming skills transfer pretty well between languages and frameworks.&lt;/p&gt;

&lt;p&gt;For 2 and 3, you need undergraduate-level probability and statistics (you should know, for example, what probability density functions and random variables are). Introductory linear algebra is also helpful here, as it underpins a lot of the data manipulations and theory behind machine learning algorithms.&lt;/p&gt;

&lt;p&gt;If you are interested in developing methods or even moving towards core machine learning research, then the mathematical and formal computer science knowledge required will obviously become much more stringent, but my advice when starting out would be to pick a problem you’re interested in, learn what you need to solve that problem, and then learn more as you go along.&lt;/p&gt;

&lt;h2 id=&quot;some-resources&quot;&gt;Some resources&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Caltech’s &lt;a href=&quot;http://justinbois.github.io/bootcamp/2018/&quot;&gt;Programming Bootcamp for Biologists&lt;/a&gt;, taught by Justin Bois&lt;/li&gt;
  &lt;li&gt;Caltech’s &lt;a href=&quot;http://bebi103.caltech.edu.s3-website-us-east-1.amazonaws.com/2018/&quot;&gt;Data Analysis in the Biological Sciences&lt;/a&gt;, taught by Justin Bois&lt;/li&gt;
  &lt;li&gt;Stanford’s &lt;a href=&quot;http://cs229.stanford.edu/syllabus.html&quot;&gt;ML Intro course&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;All the Stanford deep learning classes are well-taught and have resources online.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><summary type="html">Every so often, a chemist or biologist will ask me how they can get started in machine learning. Here is my current answer:</summary></entry><entry><title type="html">Responding to ‘That’s not biology/chemistry!</title><link href="http://localhost:4000/2019/06/11/responding.html" rel="alternate" type="text/html" title="Responding to 'That's not biology/chemistry!" /><published>2019-06-11T04:00:00-04:00</published><updated>2019-06-11T04:00:00-04:00</updated><id>http://localhost:4000/2019/06/11/responding</id><content type="html" xml:base="http://localhost:4000/2019/06/11/responding.html">&lt;p&gt;When Frances won the Nobel Prize in Chemistry, a Spanish chemist emailed her asking for advice on colleagues who claimed that their work wasn’t chemistry at all because it used machine learning:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A few analytical-chemistry people are criticizing our work because we use machine learning and neural networks as chemometrical tools for solving some identification/discrimination problems. In one particular undergraduate work we use multispectral data (imaging) and neural networks (e.g., CNN programmed in Matlab) for differentiating dogs from wolfs bite-marks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;We’ve been told this (multispectral+CNN) work is not chemistry at all, and that this particular research work is a shame for the chemistry world.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here is my (lightly-edited) response:&lt;/p&gt;

&lt;p&gt;I’m a PhD student in Frances’s lab at Caltech. She forwarded me your email and asked me to respond because my PhD has focused on using machine learning for protein engineering, so I have strong feelings about people who criticize work using machine learning as ‘not chemistry’ or ‘not biology.’&lt;/p&gt;

&lt;p&gt;Using multispectral data and a neural network to differentiate dog bites from wolf bites is really cool! It seems like an ideal application for a neural network, because there’s sound (chemical) reasons to believe that the bites should generate different spectra, but it may be very difficult to tell the spectra apart by eye.&lt;/p&gt;

&lt;p&gt;Here’s what I would say to your critics:&lt;/p&gt;

&lt;p&gt;If you collect some spectral data and use linear regression to draw some conclusions from it, nobody will argue that it’s not chemistry. Using a more complex model, such as a neural network, doesn’t magically make your work not chemistry. You’re simply using a very powerful computational tool to draw conclusions from your data. Your subject-area expertise as a chemist is what allows you to choose a reasonable model and evaluate model performance.&lt;/p&gt;

&lt;p&gt;Machine learning isn’t the solution to every problem in chemistry, but it’s already proven its ability to solve chemical problems, and will continue to do so.&lt;/p&gt;

&lt;p&gt;For example:
ACS Central Science thinks this is chemistry: &lt;a href=&quot;https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00572&quot;&gt;https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00572&lt;/a&gt; &lt;br /&gt;
Here’s one at Nature: &lt;a href=&quot;https://www.nature.com/articles/nature25978&quot;&gt;https://www.nature.com/articles/nature25978&lt;/a&gt;&lt;br /&gt;
This site has many more papers (but doesn’t seem to be updated anymore): &lt;a href=&quot;https://github.com/kangway/mlchempapers&quot;&gt;https://github.com/kangway/mlchempapers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In short, machine learning is one of many tools that belongs in the chemist’s arsenal.&lt;/p&gt;</content><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><summary type="html">When Frances won the Nobel Prize in Chemistry, a Spanish chemist emailed her asking for advice on colleagues who claimed that their work wasn’t chemistry at all because it used machine learning:</summary></entry><entry><title type="html">Reflections on AIStats2019</title><link href="http://localhost:4000/2019/05/15/reflections-on-aistats2019.html" rel="alternate" type="text/html" title="Reflections on AIStats2019" /><published>2019-05-15T04:00:00-04:00</published><updated>2019-05-15T04:00:00-04:00</updated><id>http://localhost:4000/2019/05/15/reflections-on-aistats2019</id><content type="html" xml:base="http://localhost:4000/2019/05/15/reflections-on-aistats2019.html">&lt;p&gt;Towards the end of my PhD, I decided to pivot my research more towards machine learning (with an emphasis on proteins) instead of protein engineering (with an eye towards machine learning). As part of that pivot, I worked really hard with some awesome collaborators and got a &lt;a href=&quot;https://arxiv.org/abs/1904.08102&quot;&gt;paper&lt;/a&gt; accepted to &lt;a href=&quot;https://www.aistats.org/&quot;&gt;AIStats&lt;/a&gt;. I was fortunate that &lt;a href=&quot;http://www.yisongyue.com/&quot;&gt;Yisong Yue&lt;/a&gt; and my new company were willing to fund my attendance, and so off I went to Naha, Okinawa.&lt;/p&gt;

&lt;p&gt;AIStats was my first ML/AI conference, and it was very enjoyable to be at a conference in the field that I consider my new intellectual home. A few talks, especially those on optimization, were over my head, I was able to track with nearly every paper presented. While I’ve enjoyed the previous conferences I’ve been to, I definitely found the research at this one the most interesting and stimulating.&lt;/p&gt;

&lt;p&gt;Although the conference was in Okinawa, almost everybody I met came from either California or Boston. Going halfway around the world is apparently exactly the impetus I need to meet people who live and work within 5 miles of me.&lt;/p&gt;

&lt;h3 id=&quot;themes-and-observations&quot;&gt;Themes and observations&lt;/h3&gt;

&lt;p&gt;I saw a lot of work on optimal transport, Gaussian processes, and bandits. I’ve been inspired to read up on &lt;a href=&quot;https://arxiv.org/abs/1803.00567&quot;&gt;optimal transport&lt;/a&gt;, which underpins a lot of recent theoretical work in machine learning. The bandit people definitely have the best names for things (rotting bandits! decaying bandits!). It’s just too bad the main application seems to be ad serving. AIStats is definitely has a more theoretical focus than the other major conferences: you won’t find much benchmark chasing here or many gigantic neural networks here.&lt;/p&gt;

&lt;p&gt;Perhaps not surprisingly, only 13.1% of participants were female, and only 8% were from Japan. Assuming independence, the expected number of Japanese women participants would have been around 5. I didn’t see any. Perhaps relatedly, a female graduate &lt;a href=&quot;https://www.linkedin.com/in/sunipa-dev-a12906126/&quot;&gt;student&lt;/a&gt; gave a very nice talk on &lt;a href=&quot;http://proceedings.mlr.press/v89/dev19a/dev19a.pdf&quot;&gt;attenuating bias in word vectors&lt;/a&gt;, and the first question (more of a comment) was fittingly an older white man stating that gender and racial biases are present in the data and so it’s not a problem that they’re encoded in word vectors.&lt;/p&gt;

&lt;h3 id=&quot;interesting-papers&quot;&gt;Interesting papers&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Structured Disentangled Representations.&lt;/strong&gt;&lt;br /&gt;
Babak Esmaeili, Hao Wu, Sarthak Jain, Alican Bozkurt, N Siddharth, Brooks Paige, Dana H. Brooks, Jennifer Dy, Jan-Willem Meent.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/esmaeili19a/esmaeili19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
The authors derive a hierarchical objective in order to explicitly represent the trade-offs between mutual information between data and representation, KL divergence between representation and prior, and coverage of the support of the empirical data distribution. This allows them to learn representations that disentangle both discrete and continuous (input) variables.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fast and Robust Shortest Paths on Manifolds Learned from Data.&lt;/strong&gt;&lt;br /&gt;
Georgios Arvanitidis, Soren Hauberg, Philipp Hennig, Michael Schober.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/arvanitidis19a/arvanitidis19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
The authors derive an ODE-based method for computing shortest paths and distances on Riemannian manifolds learned from data. This may have implications for using neural networks for design or for interpolation between data points.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resampled Priors for Variational Autoencoders.&lt;/strong&gt;&lt;br /&gt;
Matthias Bauer, Andriy Mnih.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/bauer19a/bauer19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
The standard normal prior used in VAEs leads to underfitting. Using Learned Accept/Reject Samplings to construct a richer prior during or after VAE training improves samples from the VAE. This is one of a few recent papers demonstrating methods for improving the VAE prior in order to get better samples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;On Multi-Cause Approaches to Causal Inference with Unobserved Counfounding: Two Cautionary Failure Cases and A Promising Alternative. Proceedings of Machine Learning Research&lt;/strong&gt;.&lt;br /&gt;
Alexander D’Amour.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/d-amour19a/d-amour19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
Alex gave a very engaging and easy-to-follow talk on why the typical approaches to causal inference over several variables simultaneously cannot succeed. Most of the talk was about how the things we’d like to do are impossible, but it didn’t come off as overly negative or pessimistic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep learning with differential Gaussian process flows.&lt;/strong&gt;&lt;br /&gt;
Pashupati Hegde, Markus Heinonen, Harri Lähdesmäki, Samuel Kaski.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/hegde19a/hegde19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
A very elegant follow-up to &lt;em&gt;Neural Ordinary Differential Equations.&lt;/em&gt; Basically, use deep GPs to warp your input space until you can get good accuracy with a linear model on top. Interestingly, Markus Heinonen, Harri Lähdesmäki are authors on &lt;em&gt;&lt;a href=&quot;https://academic.oup.com/bioinformatics/article/34/13/i274/5045756&quot;&gt;mGPFusion&lt;/a&gt;&lt;/em&gt;, which is one of my favorite ML-for-proteins papers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gaussian Process Latent Variable Alignment Learning.&lt;/strong&gt;&lt;br /&gt;
Ieva Kazlauskaite, Carl Henrik Ek, Neill Campbell.&lt;br /&gt;
[&lt;a href=&quot;http://proceedings.mlr.press/v89/kazlauskaite19a/kazlauskaite19a.pdf&quot;&gt;PDF&lt;/a&gt;]&lt;br /&gt;
Use separate GPs to simultaneously align warped time series and learn the underlying time series functions. I was hoping that this would generalize to discrete sequences, but it doesn’t seem to very easily. Nevertheless, this is a very cool Bayesian method, although I would have loved to see a full Hamiltonian Monte Carlo treatment of the posteriors.&lt;/p&gt;

&lt;h3 id=&quot;personal-lessons&quot;&gt;Personal lessons&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The best way to meet people as an introvert is to hang out with extroverted or well-connected people and let them introduce you to all their friends.&lt;/li&gt;
  &lt;li&gt;It’s ok to plan to go back to the room and rest at some point during the day. It’s better to be 100% present and ready to engage for most of the day than to be running on dregs the whole time.&lt;/li&gt;
  &lt;li&gt;This post would have been much better if I’d taken notes on my impressions of the conference itself instead of just on papers I thought were interesting. After all, the papers will still be there to read later!&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><summary type="html">Towards the end of my PhD, I decided to pivot my research more towards machine learning (with an emphasis on proteins) instead of protein engineering (with an eye towards machine learning). As part of that pivot, I worked really hard with some awesome collaborators and got a paper accepted to AIStats. I was fortunate that Yisong Yue and my new company were willing to fund my attendance, and so off I went to Naha, Okinawa.</summary></entry><entry><title type="html">A Journey from Keras to Pytorch</title><link href="http://localhost:4000/2018/03/26/pytorch-from-keras.html" rel="alternate" type="text/html" title="A Journey from Keras to Pytorch" /><published>2018-03-26T04:00:00-04:00</published><updated>2018-03-26T04:00:00-04:00</updated><id>http://localhost:4000/2018/03/26/pytorch-from-keras</id><content type="html" xml:base="http://localhost:4000/2018/03/26/pytorch-from-keras.html">&lt;p&gt;Let’s say, hypothetically speaking, that some inane taskmaster gives you a trained model in &lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt; and asks you to convert it to &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, keeping the learned weights.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;model-dimension-hell&quot;&gt;Model dimension hell&lt;/h2&gt;

&lt;h2 id=&quot;diving-into-the-batchnorm-documentation&quot;&gt;Diving into the Batchnorm documentation&lt;/h2&gt;

&lt;h2 id=&quot;linear-algebra-balrog&quot;&gt;Linear algebra Balrog&lt;/h2&gt;

&lt;h2 id=&quot;dimension-hell-part-ii&quot;&gt;Dimension hell, part II&lt;/h2&gt;</content><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><summary type="html">Let’s say, hypothetically speaking, that some inane taskmaster gives you a trained model in Keras and asks you to convert it to PyTorch, keeping the learned weights.</summary></entry><entry><title type="html">Learning the language of proteins</title><link href="http://localhost:4000/2018/03/26/learning-the-language-of-proteins.html" rel="alternate" type="text/html" title="Learning the language of proteins" /><published>2018-03-26T04:00:00-04:00</published><updated>2018-03-26T04:00:00-04:00</updated><id>http://localhost:4000/2018/03/26/learning-the-language-of-proteins</id><content type="html" xml:base="http://localhost:4000/2018/03/26/learning-the-language-of-proteins.html">&lt;p&gt;Amino acids in a protein are analogous to letters in an alphabet, short subsequences of amino acids are analogous to words in an unknown language, and a protein’s entire amino-acid sequence to a document encoding its structure and function. Therefore, I applied techniques from natural language processing to learn the language of proteins. Given a large collection of unlabeled texts, &lt;a href=&quot;https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf&quot;&gt;word2vec&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1405.4053&quot;&gt;doc2vec&lt;/a&gt; are well-established methods that learn to convert words and documents to vectors that capture their meaning. Similarly, using a large collection of unlabeled protein sequences, I trained a model that learns to vectorize proteins such that similar vectors encode similar proteins. These vectors can then be used in machine-learning models that predict protein properties from small amounts of labeled data. Models built using these vectors predict protein properties without explicit knowledge of the protein’s structure or the properties of its amino acids. Instead, the encoding process transfers information from the unlabeled sequences to the prediction problem.&lt;/p&gt;

&lt;h2 id=&quot;learn-to-encode-proteins&quot;&gt;Learn to encode proteins&lt;/h2&gt;

&lt;p&gt;I spent the first part of my PhD using machine learning to &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005786&quot;&gt;predict protein properties&lt;/a&gt; from small sets of measured sequences. The first step of a machine-learning pipeline for proteins is &lt;em&gt;encoding&lt;/em&gt; the proteins. We used what’s known as a one-hot encoding. For example, if I want to encode the DNA sequence AGTT, then I can encode each position using three 0s and one 1. Of course, for proteins, I would need 19 zeros and one 1 for each position.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/onehot.jpg&quot; alt=&quot;One-hot encoding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One-hot encodings are a good default. They do, however, have some drawbacks. One-hot encodings are space-inefficient and don’t account for the amino acid properties. There are lists and tables of amino acid properties, but different problems will require different properties, and it’s not obvious beforehand what those are. One-hot encodings are also surprisingly difficult to implement correctly. This quarter, I TAd a class where we had the students reproduce many of my results. Helping them with their homework, I noticed that the single most difficult part was making the one-hot encodings of the sequences. This gets even worse when you don’t have a TA who picks out all the sequences for you and pre-aligns them!  So if we’re training models to predict protein properties from data, why not train models to encode the proteins too?&lt;/p&gt;

&lt;p&gt;Of course, I’m not the first person to have this idea. In natural language processing, there’s an analogous problem when encoding sequences of words. Starting with word2vec, people have used learned vectors to represent words and sentences. (These are often known as ‘embeddings’ because they ‘embed’ words into a vector space). Other people have explained these in much more detail (and much better than I can). For example: &lt;a href=&quot;https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/&quot;&gt;word2vec&lt;/a&gt;, &lt;a href=&quot;https://blog.acolyer.org/2016/06/01/distributed-representations-of-sentences-and-documents/&quot;&gt;doc2vec&lt;/a&gt;. These all use the assumption that similar words occur in similar contexts to learn embeddings that place words with similar meanings close together in the embedded space. They’re generally trained on massive datasets, such as all of Wikipedia. This means that, in addition to providing a convenient representation, they also encode information from massive (and free) unlabeled datasets, which improves performance on a variety of tasks.&lt;/p&gt;

&lt;p&gt;For example, if I want to train a model to learn whether movie reviews are positive or negative, I need a dataset of reviews that are labeled as positive or negative. That usually means that somebody has to manually label the reviews, which puts an upper limit on how many examples I can obtain. On the other hand, downloading all of Wikipedia is quick and easy. Likewise, I work with small sets (&amp;lt; 300 sequences-label pairs) of labeled protein sequences, but I can also go and download 500,000+ protein sequences from UniProt.&lt;/p&gt;

&lt;p&gt;Inspired by doc2vec, I created a two-part pipeline for embedding sequences of interest. First, unsupervised doc2vec embedding models were trained on proteins downloaded from UniProt. Instead of ‘words,’ we have ‘k-mers’, which I obtain by chopping each protein up into subsequences of length &lt;em&gt;k&lt;/em&gt;. For example, for k = 3, there are three lists and each list begins at one of the first three amino acid positions of the sequence. Doc2vec learns an embedding for each overall sequence and for each k-mer. I chose to use 64-dimensional embeddings.&lt;/p&gt;

&lt;p&gt;Once I have this unsupervised embedding model, I can use it to encode sequences of interest by first chopping them into k-mers of the same size. These encodings then serve as inputs in &lt;a href=&quot;http://www.gaussianprocess.org/gpml/chapters/RW.pdf&quot;&gt;Gaussian process (pdf)&lt;/a&gt; regression models.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/figure1.png&quot; alt=&quot;Scheme&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;encodings-enable-accurate-models&quot;&gt;Encodings enable accurate models&lt;/h2&gt;

&lt;p&gt;I tested embeddings on four protein prediction tasks, comparing their performance to one-hot encodings of sequence or sequence and structure, encodings based on physical properties (&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/9847231&quot;&gt;AAIndex&lt;/a&gt; and &lt;a href=&quot;https://academic.oup.com/bioinformatics/article/31/21/3429/194375&quot;&gt;ProFET&lt;/a&gt;), and &lt;a href=&quot;https://academic.oup.com/bioinformatics/article/20/4/467/192308&quot;&gt;string mismatch kernels&lt;/a&gt;. For all of these tasks, the embeddings performed at least as well as the other methods despite not using alignments, structural information, or physical properties. For example, here are the test predictions for channelrhodopsin localization, where embeddings have both the highest Kendall Tau and lowest mean absolute deviation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/localization_predictions.jpg&quot; alt=&quot;Predictions&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I chose to use 64-dimensional embeddings, but it turns out that I can still train reasonably accurate models after reducing the number of embedding dimensions to 16.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vary_d_curve.jpg&quot; alt=&quot;d curve&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Think about this for a minute. The protein of interest has over 200 amino acids. Protein translation and trafficking is a multi-step, poorly-understood process. &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005786&quot;&gt;Previously&lt;/a&gt;, we had found that there are no simple sequence or structure predictors of membrane localization. But I can store enough information in 16 numbers to predict how well it will be trafficked to the cell plasma membrane.&lt;/p&gt;

&lt;h2 id=&quot;further-reading&quot;&gt;Further reading&lt;/h2&gt;

&lt;p&gt;The full paper is available at Bioinformatics:  &lt;a href=&quot;https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/bty178/4951834?guestAccessKey=aa420938-7c4a-4c47-8763-bad82d936d10&quot;&gt;Learned protein embeddings for machine learning&lt;/a&gt;, and code to reproduce the results is available &lt;a href=&quot;https://github.com/fhalab/embeddings_reproduction&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Kevin Kaichuang Yang (楊凱筌)</name></author><summary type="html">Amino acids in a protein are analogous to letters in an alphabet, short subsequences of amino acids are analogous to words in an unknown language, and a protein’s entire amino-acid sequence to a document encoding its structure and function. Therefore, I applied techniques from natural language processing to learn the language of proteins. Given a large collection of unlabeled texts, word2vec and doc2vec are well-established methods that learn to convert words and documents to vectors that capture their meaning. Similarly, using a large collection of unlabeled protein sequences, I trained a model that learns to vectorize proteins such that similar vectors encode similar proteins. These vectors can then be used in machine-learning models that predict protein properties from small amounts of labeled data. Models built using these vectors predict protein properties without explicit knowledge of the protein’s structure or the properties of its amino acids. Instead, the encoding process transfers information from the unlabeled sequences to the prediction problem.</summary></entry></feed>